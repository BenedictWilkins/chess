{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7297e5d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 77\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#print(image_grid.shape)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#J.images(image_grid.reshape(-1, *image_grid.shape[-3:]))\u001b[39;00m\n\u001b[1;32m     76\u001b[0m text \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mtokenize([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdog\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 77\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlocate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimage_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m logits \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mimage_logits\n\u001b[1;32m     79\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mgrid_shape,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[97], line 36\u001b[0m, in \u001b[0;36mlocate\u001b[0;34m(imgs, text)\u001b[0m\n\u001b[1;32m     34\u001b[0m image_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_image(imgs)\n\u001b[1;32m     35\u001b[0m text_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_text(text)\n\u001b[0;32m---> 36\u001b[0m logits_per_image, logits_per_text \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m image_features \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m image_features\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m text_features \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m text_features\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/clip/model.py:359\u001b[0m, in \u001b[0;36mCLIP.forward\u001b[0;34m(self, image, text)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, text):\n\u001b[0;32m--> 359\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     text_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_text(text)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# normalized features\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/clip/model.py:341\u001b[0m, in \u001b[0;36mCLIP.encode_image\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/clip/model.py:232\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    229\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_pre(x)\n\u001b[1;32m    231\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NLD -> LND\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# LND -> NLD\u001b[39;00m\n\u001b[1;32m    235\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_post(x[:, \u001b[38;5;241m0\u001b[39m, :])\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/clip/model.py:203\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/clip/model.py:190\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 190\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    191\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x))\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/clip/model.py:162\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    161\u001b[0m     orig_type \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m--> 162\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtype(orig_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import clip\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.io as io\n",
    "import math\n",
    "import itertools\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import jnu as J\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def load_mp4(video_path, frame_rate):\n",
    "    video = io.VideoReader(video_path, \"video\")\n",
    "    metadata = video.get_metadata()\n",
    "    duration = metadata['video']['duration'][0]\n",
    "    fps = metadata['video']['fps'][0]\n",
    "    est_total_frames = (duration * fps)\n",
    "    des_total_frames = (duration * frame_rate)\n",
    "    skip = math.ceil(est_total_frames / des_total_frames)\n",
    "    frames = []\n",
    "    for frame in tqdm(itertools.islice(video, 0, None, skip), desc=\"loading video\"):\n",
    "        frames.append(frame['data'].float() / 255.)\n",
    "    return torch.stack(frames)\n",
    "\n",
    "def locate(imgs, text):\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(imgs)\n",
    "        text_features = model.encode_text(text)\n",
    "        logits_per_image, logits_per_text = model(imgs, text)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "        return SimpleNamespace(similarity=similarity, \n",
    "                               image_features=image_features, text_features=text_features,\n",
    "                               image_logits=logits_per_image, text_logits=logits_per_text)\n",
    "    \n",
    "def grid(imgs, size=224, stride=224//4):\n",
    "    imgs = transforms.ToTensor()(imgs)\n",
    "    l = len(imgs.shape)\n",
    "    imgs = imgs.unfold(l-2, size, stride)\n",
    "    imgs = imgs.unfold(l-1, size, stride)\n",
    "    reshape = np.arange(len(imgs.shape)).tolist()\n",
    "    c = reshape[l-3]\n",
    "    del reshape[l-3]\n",
    "    reshape.insert(l-1,c)\n",
    "    return imgs.permute(*reshape)\n",
    "\n",
    "resize = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224), interpolation=Image.BICUBIC, antialias=True),\n",
    "        transforms.CenterCrop((224, 224)),\n",
    "    ])\n",
    "normalize = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "image = Image.open(\"img/dog.jpg\")#.unsqueeze(0)\n",
    "#image = normalize(image)\n",
    "image_grid = grid(image)\n",
    "grid_shape = image_grid.shape[:-3]\n",
    "\n",
    "#print(image_grid.shape)\n",
    "#J.images(image_grid.reshape(-1, *image_grid.shape[-3:]))\n",
    "\n",
    "text = clip.tokenize([\"dog\"]).to(device)\n",
    "result = locate(image_grid.reshape(-1,*image_grid.shape[-3:]), text)\n",
    "logits = result.image_logits\n",
    "logits = logits.reshape(*grid_shape,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "logits = (logits - logits.min()) / (logits.max() - logits.min())\n",
    "sb.heatmap(logits.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b222bf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab855ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ce4619d0ef4010a8e0c40239a648e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading video: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c5aeba0da7484bbf924dad951be7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='x', layout=Layout(width='99%'), max=31), Output()), _dom…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d1c0bcaf1e4a4fbc2524840ac4d0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=1080, width=1920),), layout=Layout(align_items='center', display='flex', flex_flo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<jnu.image._image.Image at 0x7f9f3f894910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./video/chess-02.mp4\"\n",
    "imgs = load_mp4(file_path, 2).to(device)\n",
    "J.images(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a08cae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20.6530, 22.8280],\n",
      "        [21.0456, 22.1278],\n",
      "        [21.6541, 22.4598],\n",
      "        [20.9627, 22.4379],\n",
      "        [20.0259, 21.4705],\n",
      "        [20.1362, 20.7447],\n",
      "        [21.7284, 22.6539],\n",
      "        [20.9259, 22.1536],\n",
      "        [20.7730, 21.9828],\n",
      "        [20.3810, 20.7559],\n",
      "        [21.7437, 21.7931],\n",
      "        [23.6621, 21.3526],\n",
      "        [23.7533, 19.8215],\n",
      "        [25.3439, 21.5343],\n",
      "        [28.8745, 20.2418],\n",
      "        [28.2159, 19.3399],\n",
      "        [25.9313, 20.2448],\n",
      "        [27.1215, 19.3355],\n",
      "        [29.0941, 19.7587],\n",
      "        [31.2711, 20.1906],\n",
      "        [30.7352, 19.4998],\n",
      "        [31.1156, 19.7632],\n",
      "        [31.8747, 20.3074],\n",
      "        [31.3972, 19.9737],\n",
      "        [31.4849, 20.8653],\n",
      "        [30.1148, 20.2362],\n",
      "        [29.2274, 18.3738],\n",
      "        [19.7151, 20.2330],\n",
      "        [19.9522, 22.4351],\n",
      "        [18.9488, 20.6751],\n",
      "        [19.8379, 23.9496],\n",
      "        [22.0884, 23.1437]])\n"
     ]
    }
   ],
   "source": [
    "text = clip.tokenize([\"chess board\", \"dog\", \"face\", \"human\", \"\"]).to(device)\n",
    "probs, img_f, text_f = locate(preprocess(imgs), text)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b88be35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846.9667244850218 55.99693333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd037da728849378ec4f063e2056317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading video: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[252, 252, 252,  ...,  99, 104, 106],\n",
      "           [252, 252, 252,  ..., 101, 106, 107],\n",
      "           [252, 252, 252,  ..., 106, 109, 112],\n",
      "           ...,\n",
      "           [ 13,  13,  13,  ...,  87,  86,  86],\n",
      "           [ 13,  13,  13,  ...,  87,  85,  84],\n",
      "           [ 13,  13,  13,  ...,  86,  84,  81]],\n",
      "\n",
      "          [[252, 252, 252,  ...,  82,  87,  89],\n",
      "           [252, 252, 252,  ...,  84,  89,  90],\n",
      "           [252, 252, 252,  ...,  89,  92,  95],\n",
      "           ...,\n",
      "           [ 13,  13,  13,  ...,  77,  76,  76],\n",
      "           [ 13,  13,  13,  ...,  77,  75,  74],\n",
      "           [ 13,  13,  13,  ...,  76,  74,  71]],\n",
      "\n",
      "          [[252, 252, 252,  ...,  85,  90,  92],\n",
      "           [252, 252, 252,  ...,  87,  92,  93],\n",
      "           [252, 252, 252,  ...,  92,  95,  98],\n",
      "           ...,\n",
      "           [  8,   8,   8,  ...,  81,  80,  80],\n",
      "           [  8,   8,   8,  ...,  81,  79,  78],\n",
      "           [  8,   8,   8,  ...,  80,  78,  75]]],\n",
      "\n",
      "\n",
      "         [[[252, 252, 252,  ..., 101, 101, 101],\n",
      "           [252, 252, 252,  ..., 103, 103, 103],\n",
      "           [252, 252, 252,  ..., 103, 103, 104],\n",
      "           ...,\n",
      "           [ 16,  16,  16,  ...,  55,  56,  54],\n",
      "           [ 17,  17,  17,  ...,  55,  55,  54],\n",
      "           [ 19,  19,  18,  ...,  53,  53,  54]],\n",
      "\n",
      "          [[252, 252, 252,  ...,  97,  97,  97],\n",
      "           [252, 252, 252,  ...,  99,  99,  99],\n",
      "           [252, 252, 252,  ..., 102, 102, 103],\n",
      "           ...,\n",
      "           [ 14,  14,  14,  ...,  53,  54,  52],\n",
      "           [ 15,  15,  15,  ...,  53,  53,  52],\n",
      "           [ 17,  17,  16,  ...,  51,  51,  52]],\n",
      "\n",
      "          [[252, 252, 252,  ...,  91,  91,  91],\n",
      "           [252, 252, 252,  ...,  93,  93,  93],\n",
      "           [252, 252, 252,  ...,  93,  95,  96],\n",
      "           ...,\n",
      "           [ 10,  10,  10,  ...,  49,  50,  48],\n",
      "           [ 11,  11,  11,  ...,  49,  49,  48],\n",
      "           [ 13,  13,  12,  ...,  47,  47,  48]]],\n",
      "\n",
      "\n",
      "         [[[ 51,  51,  51,  ..., 152, 153, 152],\n",
      "           [ 51,  51,  51,  ..., 152, 153, 152],\n",
      "           [ 51,  51,  51,  ..., 150, 152, 150],\n",
      "           ...,\n",
      "           [ 17,  17,  17,  ..., 129, 127, 124],\n",
      "           [ 17,  17,  17,  ..., 129, 128, 124],\n",
      "           [ 17,  17,  17,  ..., 130, 129, 125]],\n",
      "\n",
      "          [[ 49,  49,  49,  ..., 147, 148, 147],\n",
      "           [ 49,  49,  49,  ..., 147, 148, 147],\n",
      "           [ 49,  49,  49,  ..., 145, 147, 145],\n",
      "           ...,\n",
      "           [ 15,  15,  15,  ..., 128, 126, 123],\n",
      "           [ 15,  15,  15,  ..., 130, 129, 125],\n",
      "           [ 15,  15,  15,  ..., 131, 130, 126]],\n",
      "\n",
      "          [[ 29,  29,  29,  ..., 149, 150, 149],\n",
      "           [ 29,  29,  29,  ..., 149, 150, 149],\n",
      "           [ 29,  29,  29,  ..., 147, 149, 147],\n",
      "           ...,\n",
      "           [ 11,  11,  11,  ..., 121, 119, 116],\n",
      "           [ 11,  11,  11,  ..., 122, 121, 117],\n",
      "           [ 11,  11,  11,  ..., 123, 122, 118]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[150, 151, 154,  ...,  37,  37,  37],\n",
      "           [151, 153, 157,  ...,  37,  37,  37],\n",
      "           [154, 157, 159,  ...,  37,  37,  37],\n",
      "           ...,\n",
      "           [ 27,  27,  27,  ...,   8,   8,   9],\n",
      "           [ 27,  27,  27,  ...,   8,   8,   9],\n",
      "           [ 27,  27,  27,  ...,   8,   8,   9]],\n",
      "\n",
      "          [[149, 150, 153,  ...,  30,  30,  30],\n",
      "           [150, 152, 156,  ...,  30,  30,  30],\n",
      "           [153, 156, 158,  ...,  30,  30,  30],\n",
      "           ...,\n",
      "           [ 26,  26,  26,  ...,   8,   8,   9],\n",
      "           [ 26,  26,  26,  ...,   8,   8,   9],\n",
      "           [ 26,  26,  26,  ...,   8,   8,   9]],\n",
      "\n",
      "          [[152, 153, 156,  ...,  28,  28,  28],\n",
      "           [153, 155, 159,  ...,  28,  28,  28],\n",
      "           [156, 159, 161,  ...,  28,  28,  28],\n",
      "           ...,\n",
      "           [ 17,  17,  17,  ...,   8,   8,   9],\n",
      "           [ 17,  17,  17,  ...,   8,   8,   9],\n",
      "           [ 17,  17,  17,  ...,   8,   8,   9]]],\n",
      "\n",
      "\n",
      "         [[[133, 133, 133,  ...,  38,  38,  38],\n",
      "           [133, 133, 133,  ...,  38,  38,  38],\n",
      "           [135, 135, 135,  ...,  40,  38,  38],\n",
      "           ...,\n",
      "           [208, 209, 209,  ...,  21,  22,  22],\n",
      "           [208, 209, 209,  ...,  21,  22,  22],\n",
      "           [208, 209, 209,  ...,  21,  22,  22]],\n",
      "\n",
      "          [[105, 105, 105,  ...,  31,  31,  31],\n",
      "           [105, 105, 105,  ...,  31,  31,  31],\n",
      "           [105, 105, 105,  ...,  33,  31,  31],\n",
      "           ...,\n",
      "           [208, 209, 209,  ...,  15,  16,  16],\n",
      "           [208, 209, 209,  ...,  15,  16,  16],\n",
      "           [208, 209, 209,  ...,  15,  16,  16]],\n",
      "\n",
      "          [[ 10,  10,  10,  ...,  29,  29,  29],\n",
      "           [ 10,  10,  10,  ...,  29,  29,  29],\n",
      "           [ 11,  11,  11,  ...,  31,  29,  29],\n",
      "           ...,\n",
      "           [205, 206, 206,  ...,  10,  11,  11],\n",
      "           [205, 206, 206,  ...,  10,  11,  11],\n",
      "           [205, 206, 206,  ...,  10,  11,  11]]],\n",
      "\n",
      "\n",
      "         [[[138, 138, 138,  ...,  49,  49,  49],\n",
      "           [138, 138, 138,  ...,  49,  49,  49],\n",
      "           [139, 139, 139,  ...,  49,  49,  49],\n",
      "           ...,\n",
      "           [220, 221, 221,  ...,  18,  18,  18],\n",
      "           [220, 220, 221,  ...,  18,  18,  18],\n",
      "           [220, 220, 221,  ...,  18,  18,  18]],\n",
      "\n",
      "          [[120, 120, 120,  ...,  45,  45,  45],\n",
      "           [120, 120, 120,  ...,  45,  45,  45],\n",
      "           [121, 121, 121,  ...,  45,  45,  45],\n",
      "           ...,\n",
      "           [220, 221, 221,  ...,  17,  17,  17],\n",
      "           [220, 220, 221,  ...,  17,  17,  17],\n",
      "           [220, 220, 221,  ...,  17,  17,  17]],\n",
      "\n",
      "          [[ 20,  20,  20,  ...,  39,  39,  39],\n",
      "           [ 20,  20,  20,  ...,  39,  39,  39],\n",
      "           [ 21,  21,  21,  ...,  39,  39,  39],\n",
      "           ...,\n",
      "           [220, 221, 221,  ...,   6,   6,   6],\n",
      "           [220, 220, 221,  ...,   6,   6,   6],\n",
      "           [220, 220, 221,  ...,   6,   6,   6]]]]], dtype=torch.uint8)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#image = preprocess(Image.open(\"./img/chess1.jpg\")).unsqueeze(0).to(device)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_image(\u001b[43mimage\u001b[49m)\n\u001b[1;32m     13\u001b[0m     text_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_text(text)\n\u001b[1;32m     15\u001b[0m     logits_per_image, logits_per_text \u001b[38;5;241m=\u001b[39m model(image, text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "chess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
